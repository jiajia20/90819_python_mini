{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting Reddit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt \n",
    "start_date = int(dt.datetime(2023, 2, 3).timestamp()) \n",
    "end_date = int(dt.datetime(2022, 3, 31).timestamp())\n",
    "\n",
    "print(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull data from Reddit API\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime as dt\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "#set up the url \n",
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "#set up the parameters\n",
    "# collect from r/conspiracy subreddit\n",
    "# collect 100 posts at a time\n",
    "# collect posts from 3 February 2023 to April 2023\n",
    "# retrive only data contain keywords \"ohio\"\n",
    "\n",
    "params = {\n",
    "    'subreddit': 'conspiracy',\n",
    "    'size': 1000,\n",
    "    'after': start_date,\n",
    "    'q': 'ohio'\n",
    "}\n",
    "#pull the data\n",
    "res = requests.get(url, params)\n",
    "#check the status code\n",
    "res.status_code\n",
    "\n",
    "#convert the data to a json file\n",
    "data = res.json()\n",
    "#check the data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data to a dataframe  \n",
    "df = pd.DataFrame(data['data'])\n",
    "#check the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create visualization of post per day\n",
    "df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "df['date'] = df['created_utc'].dt.date\n",
    "grouped = df.groupby('date')['id'].count()\n",
    "grouped.plot(kind='line', figsize=(10,5))\n",
    "plt.title(f'Daily Submissions to r/Conspiracy with keyword \"ohio\"')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Submissions')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data collection run 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the url \n",
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "#set up the parameters\n",
    "# collect from r/conspiracy subreddit\n",
    "# collect 100 posts at a time\n",
    "# collect posts from 3 February 2023 to April 2023\n",
    "# retrive only data contain keywords \"ohio\"\n",
    "\n",
    "params = {\n",
    "    'subreddit': 'conspiracy',\n",
    "    'size': 1000,\n",
    "    'after': start_date,\n",
    "    'q': 'train'\n",
    "}\n",
    "#pull the data\n",
    "res = requests.get(url, params)\n",
    "#check the status code\n",
    "res.status_code\n",
    "\n",
    "#convert the data to a json file\n",
    "data = res.json()\n",
    "#check the data\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['data'])\n",
    "#check the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create visualization of post per day\n",
    "df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "df['date'] = df['created_utc'].dt.date\n",
    "grouped = df.groupby('date')['id'].count()\n",
    "grouped.plot(kind='line', figsize=(10,5))\n",
    "plt.title(f'Daily Submissions to r/Conspiracy with keyword \"train\"')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Submissions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the url \n",
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "#set up the parameters\n",
    "# collect from r/conspiracy subreddit\n",
    "# collect 100 posts at a time\n",
    "# collect posts from 3 February 2023 to April 2023\n",
    "# retrive only data contain keywords \"ohio\"\n",
    "\n",
    "params = {\n",
    "    'subreddit': 'conspiracy',\n",
    "    'size': 1000,\n",
    "    'after': start_date,\n",
    "    'q': 'derailment'\n",
    "}\n",
    "#pull the data\n",
    "res = requests.get(url, params)\n",
    "#check the status code\n",
    "res.status_code\n",
    "\n",
    "#convert the data to a json file\n",
    "data = res.json()\n",
    "#check the data\n",
    "df = pd.DataFrame(data['data'])\n",
    "\n",
    "\n",
    "# create visualization of post per day\n",
    "df['created_utc'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "df['date'] = df['created_utc'].dt.date\n",
    "grouped = df.groupby('date')['id'].count()\n",
    "grouped.plot(kind='line', figsize=(10,5))\n",
    "plt.title(f'Daily Submissions to r/Conspiracy with keyword \"derailment\"')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Submissions')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
